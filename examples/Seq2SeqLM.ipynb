{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68675e3b",
   "metadata": {},
   "source": [
    "# Knowledge Distillation with hf_distiller\n",
    "This notebook demonstrates:\n",
    "1. Loading a teacher model from Hugging Face Hub\n",
    "2. Creating a smaller student model\n",
    "3. Preparing a toy dataset\n",
    "4. Training the student using knowledge distillation\n",
    "5. Visualizing training loss and logits comparison\n",
    "\n",
    "You can replace the demo dataset with your own dataset for real training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980f2725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0 — Install requirements (run only once)\n",
    "# !pip install --no-deps git+https://github.com/Dhiraj309/transformers_distillation.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22c2484",
   "metadata": {},
   "source": [
    "## Step 1 — Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acab9153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from transformers import AutoTokenizer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from transformers_distillation.models import load_teacher, load_student\n",
    "from transformers_distillation import DistillTrainer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4223dcc",
   "metadata": {},
   "source": [
    "## Step 2 — Load Teacher Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d061642",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'google/flan-t5-small'\n",
    "\n",
    "# Load teacher and tokenizer\n",
    "teacher = load_teacher(model_name_or_path=MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"Teacher model loaded:\", teacher.__class__.__name__)\n",
    "print(\"Tokenizer vocab size:\", len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3967d783",
   "metadata": {},
   "source": [
    "## Step 3 — Create Student Model\n",
    "A smaller architecture for faster inference and lower memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e2af04",
   "metadata": {},
   "outputs": [],
   "source": [
    "student = load_student(\n",
    "    model_name_or_path=MODEL_NAME,\n",
    "    from_scratch=True,\n",
    "    n_layers=4,\n",
    "    n_heads=4,\n",
    "    n_embd=256,\n",
    "    is_pretrained=False\n",
    ")\n",
    "print(\"Student model created:\", student.__class__.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7a02c4",
   "metadata": {},
   "source": [
    "## Step 4 — Prepare Dataset\n",
    "Small in-memory dataset for demonstration. Replace with your own data for real training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60678685",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [\n",
    "    \"Translate English to French: Hello world!\",\n",
    "    \"Translate English to French: The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Translate English to French: Artificial intelligence is transforming industries.\",\n",
    "    \"Translate English to French: Once upon a time, there was a curious developer.\",\n",
    "    \"Translate English to French: PyTorch makes deep learning both fun and powerful.\"\n",
    "]\n",
    "\n",
    "targets = [\n",
    "    \"Bonjour le monde!\",\n",
    "    \"Le renard brun rapide saute par-dessus le chien paresseux.\",\n",
    "    \"L'intelligence artificielle transforme les industries.\",\n",
    "    \"Il était une fois un développeur curieux.\",\n",
    "    \"PyTorch rend l'apprentissage profond à la fois amusant et puissant.\"\n",
    "]\n",
    "\n",
    "dataset = Dataset.from_dict({\"source\": sources, \"target\": targets})\n",
    "\n",
    "def tokenize(batch):\n",
    "    # Tokenize encoder inputs\n",
    "    model_inputs = tokenizer(\n",
    "        batch[\"source\"],\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    # Tokenize decoder targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            batch[\"target\"],\n",
    "            max_length=128,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\"\n",
    "        )[\"input_ids\"]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=[\"source\", \"target\"])\n",
    "eval_dataset = tokenized_dataset.select(range(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c33d328",
   "metadata": {},
   "source": [
    "## Step 5 — Define Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f72350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./student-llm',\n",
    "    per_device_train_batch_size=1,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=1,\n",
    "    save_steps=100,\n",
    "    save_total_limit=5,\n",
    "    report_to='none',\n",
    "    lr_scheduler_type='cosine',\n",
    "    warmup_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6300de8b",
   "metadata": {},
   "source": [
    "## Step 6 — Initialize Distillation Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a2318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DistillTrainer(\n",
    "    teacher_model=teacher,\n",
    "    student_model=student,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    training_args=training_args,\n",
    "    kd_alpha=0.5,\n",
    "    temperature=2.0,\n",
    "    is_pretrained=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbd3fe9",
   "metadata": {},
   "source": [
    "## Step 7 — Train Student Model\n",
    "The student learns from both teacher outputs and ground truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8415670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of loss for visualization\n",
    "trainer_state = trainer.train()\n",
    "losses = trainer_state.training_loss if hasattr(trainer_state, 'training_loss') else []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3320dc18",
   "metadata": {},
   "source": [
    "## Step 8 — Evaluate Student Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db37670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate(eval_dataset = eval_dataset)\n",
    "print('Evaluation results:', results)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
