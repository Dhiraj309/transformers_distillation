{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Distillation with hf_distiller\n",
    "This notebook demonstrates:\n",
    "1. Loading a teacher model from Hugging Face Hub\n",
    "2. Creating a smaller student model\n",
    "3. Preparing a toy dataset\n",
    "4. Training the student using knowledge distillation\n",
    "5. Visualizing training loss and logits comparison\n",
    "\n",
    "You can replace the demo dataset with your own dataset for real training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0 — Install requirements (run only once)\n",
    "# !pip install --no-deps git+https://github.com/Dhiraj309/transformers_distillation.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 — Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from transformers import AutoTokenizer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from transformers_distillation.models import load_teacher, load_student\n",
    "from transformers_distillation import DistillTrainer\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure src/ is in Python path (adjust if necessary)\n",
    "sys.path.append(os.path.join(os.getcwd(), 'src'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 — Load Teacher Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'HuggingFaceTB/SmolLM2-135M'\n",
    "\n",
    "# Load teacher and tokenizer\n",
    "teacher = load_teacher(model_name_or_path=MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"Teacher model loaded:\", teacher.__class__.__name__)\n",
    "print(\"Tokenizer vocab size:\", len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 — Create Student Model\n",
    "A smaller architecture for faster inference and lower memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student = load_student(\n",
    "    model_name_or_path=MODEL_NAME,\n",
    "    from_scratch=True,\n",
    "    n_layers=4,\n",
    "    n_heads=4,\n",
    "    n_embd=256,\n",
    "    is_pretrained=False\n",
    ")\n",
    "print(\"Student model created:\", student.__class__.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 — Prepare Dataset\n",
    "Small in-memory dataset for demonstration. Replace with your own data for real training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Hello world!\",\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Artificial intelligence is transforming industries.\",\n",
    "    \"Once upon a time, there was a curious developer.\",\n",
    "    \"PyTorch makes deep learning both fun and powerful.\"\n",
    "]\n",
    "dataset = Dataset.from_dict({\"text\": texts})\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], max_length=128, padding=True, truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=['text'])\n",
    "print(\"Tokenized example:\", tokenized_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 — Define Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./student-llm',\n",
    "    per_device_train_batch_size=1,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=1,\n",
    "    save_steps=100,\n",
    "    save_total_limit=5,\n",
    "    report_to='none',\n",
    "    lr_scheduler_type='cosine',\n",
    "    warmup_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 — Initialize Distillation Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DistillTrainer(\n",
    "    teacher_model=teacher,\n",
    "    student_model=student,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    training_args=training_args,\n",
    "    kd_alpha=0.5,\n",
    "    temperature=2.0,\n",
    "    is_pretrained=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 — Train Student Model\n",
    "The student learns from both teacher outputs and ground truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of loss for visualization\n",
    "trainer_state = trainer.train()\n",
    "losses = trainer_state.training_loss if hasattr(trainer_state, 'training_loss') else []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 — Visualize Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if losses:\n",
    "    plt.plot(losses)\n",
    "    plt.title('Training Loss over Steps')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No loss history available. Training ran very quickly with few steps.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 — Evaluate Student Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate()\n",
    "print('Evaluation results:', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10 — Compare Teacher vs Student logits for an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"Artificial intelligence is fascinating.\"\n",
    "inputs = tokenizer(example_text, return_tensors='pt')\n",
    "\n",
    "with torch.no_grad():\n",
    "    teacher_logits = teacher(**inputs).logits\n",
    "    student_logits = student(**inputs).logits\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(teacher_logits[0].cpu(), label='Teacher logits')\n",
    "plt.plot(student_logits[0].cpu(), label='Student logits')\n",
    "plt.title('Teacher vs Student logits')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
