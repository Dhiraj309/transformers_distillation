{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb561b16",
   "metadata": {},
   "source": [
    "# Knowledge Distillation with hf_distiller\n",
    "This notebook demonstrates:\n",
    "1. Loading a teacher model from Hugging Face Hub\n",
    "2. Creating a smaller student model\n",
    "3. Preparing a toy dataset\n",
    "4. Training the student using knowledge distillation\n",
    "5. Visualizing training loss and logits comparison\n",
    "\n",
    "You can replace the demo dataset with your own dataset for real training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d48c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0 — Install requirements (run only once)\n",
    "# !pip install --no-deps git+https://github.com/Dhiraj309/transformers_distillation.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83171e73",
   "metadata": {},
   "source": [
    "## Step 1 — Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d8b9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from transformers import AutoTokenizer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from transformers_distillation.models import load_teacher, load_student\n",
    "from transformers_distillation import DistillTrainer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e835a210",
   "metadata": {},
   "source": [
    "## Step 2 — Load Teacher Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95a85a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'google-bert/bert-base-uncased'\n",
    "\n",
    "# Load teacher and tokenizer\n",
    "teacher = load_teacher(model_name_or_path=MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"Teacher model loaded:\", teacher.__class__.__name__)\n",
    "print(\"Tokenizer vocab size:\", len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7527041b",
   "metadata": {},
   "source": [
    "## Step 3 — Create Student Model\n",
    "A smaller architecture for faster inference and lower memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbc0e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "student = load_student(\n",
    "    model_name_or_path=MODEL_NAME,\n",
    "    from_scratch=True,\n",
    "    n_layers=4,\n",
    "    n_heads=4,\n",
    "    n_embd=256,\n",
    "    is_pretrained=False\n",
    ")\n",
    "print(\"Student model created:\", student.__class__.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef99b6f9",
   "metadata": {},
   "source": [
    "## Step 4 — Prepare Dataset\n",
    "Small in-memory dataset for demonstration. Replace with your own data for real training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e10a9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Hello world!\",\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Artificial intelligence is transforming industries.\",\n",
    "    \"Once upon a time, there was a curious developer.\",\n",
    "    \"PyTorch makes deep learning both fun and powerful.\"\n",
    "]\n",
    "dataset = Dataset.from_dict({\"text\": texts})\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], max_length=128, padding=True, truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=['text'])\n",
    "eval_dataset = tokenized_dataset.select(range(1))\n",
    "print(\"Tokenized example:\", tokenized_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e86cd8e",
   "metadata": {},
   "source": [
    "## Step 5 — Define Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1a0060",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./student-llm',\n",
    "    per_device_train_batch_size=1,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=1,\n",
    "    save_steps=100,\n",
    "    save_total_limit=5,\n",
    "    report_to='none',\n",
    "    lr_scheduler_type='cosine',\n",
    "    warmup_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824de177",
   "metadata": {},
   "source": [
    "## Step 6 — Initialize Distillation Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7793974",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DistillTrainer(\n",
    "    teacher_model=teacher,\n",
    "    student_model=student,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    training_args=training_args,\n",
    "    kd_alpha=0.5,\n",
    "    temperature=2.0,\n",
    "    is_pretrained=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da02536",
   "metadata": {},
   "source": [
    "## Step 7 — Train Student Model\n",
    "The student learns from both teacher outputs and ground truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91af179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of loss for visualization\n",
    "trainer_state = trainer.train()\n",
    "losses = trainer_state.training_loss if hasattr(trainer_state, 'training_loss') else []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44059de0",
   "metadata": {},
   "source": [
    "## Step 8 — Evaluate Student Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c6f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate(eval_dataset = eval_dataset)\n",
    "print('Evaluation results:', results)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
